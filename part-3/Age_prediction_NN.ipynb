{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1A5s3D300NXX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader,IterableDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.12.0-cp38-cp38-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (3.7.4.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (8.2.0)\n",
      "Collecting torch==1.11.0\n",
      "  Downloading torch-1.11.0-cp38-none-macosx_10_9_x86_64.whl (129.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 129.9 MB 140 kB/s eta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages (from requests->torchvision) (1.26.4)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.2\n",
      "    Uninstalling torch-1.10.2:\n",
      "      Successfully uninstalled torch-1.10.2\n",
      "Successfully installed torch-1.11.0 torchvision-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UBgfOi7VZgxm"
   },
   "outputs": [],
   "source": [
    "oppScrData = pd.read_excel ('OppScrData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zT0tS-hvfVfC"
   },
   "outputs": [],
   "source": [
    "def clean_ct_data(oppScrData):\n",
    "    # Delete rows with empty values\n",
    "    ct_data= oppScrData[[\"L1_HU_BMD\", \"TAT Area (cm2)\", 'Total Body                Area EA (cm2)',\n",
    "       'VAT Area (cm2)', 'SAT Area (cm2)', 'VAT/SAT     Ratio', 'Muscle HU',\n",
    "       ' Muscle Area (cm2)', 'L3 SMI (cm2/m2)', 'AoCa        Agatston',\n",
    "       'Liver HU    (Median)', 'Age at CT']]\n",
    "    n = ct_data.shape[0]\n",
    "    preprocessed_ct_data = []\n",
    "    for i in range(n):\n",
    "        row = ct_data.loc[i]\n",
    "        ignore = False\n",
    "        for j in row:\n",
    "          if pd.isna(j) or j == ' ': # There is an empty string somewhere in Liver column\n",
    "            ignore = True\n",
    "            break\n",
    "        if not ignore:\n",
    "          preprocessed_ct_data.append(row)\n",
    "    return np.array(preprocessed_ct_data, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tEz5RjTvgE1o"
   },
   "outputs": [],
   "source": [
    "def normalize_ct_data(ct_data):\n",
    "    n = ct_data.shape[1]    \n",
    "    for i in range(n-1):\n",
    "      ct_data[:,i] = (ct_data[:,i] - np.min(ct_data[:,i]))/(np.max(ct_data[:,i])- np.min(ct_data[:,i]))\n",
    "    return ct_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_1B1GORmev3F"
   },
   "outputs": [],
   "source": [
    "oppScrData = pd.read_excel ('OppScrData.xlsx')  \n",
    "ct_data = clean_ct_data(oppScrData)\n",
    "ct_data= normalize_ct_data(ct_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lSDGb9QFbwxy"
   },
   "outputs": [],
   "source": [
    "y = ct_data[:,-1]\n",
    "x = (ct_data[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hIFoIYPJbqtd"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XjU44f9rGhH7"
   },
   "outputs": [],
   "source": [
    "class CT_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.ct_data = X\n",
    "        self.age = y \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ct_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ct_data = self.ct_data[idx]     \n",
    "        age = np.array(self.age[idx], dtype=np.float32)\n",
    "        return torch.from_numpy(ct_data), torch.from_numpy(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9A8n-S3PQ06Q"
   },
   "outputs": [],
   "source": [
    "a = CT_Dataset(X=X_train, y = y_train)\n",
    "train_set = DataLoader(a, batch_size=64, shuffle=True)\n",
    "# train_set = DataLoader(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5WR8JdUB_QxC"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  return nn.Sequential(\n",
    "    nn.Linear(11, 64),\n",
    "    nn.BatchNorm1d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.BatchNorm1d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 10),\n",
    "    nn.BatchNorm1d(10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1)\n",
    "    )\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "485ik2ZeAD_A",
    "outputId": "9d43bcb7-227f-4a28-9730-819b450ccf2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([54])) that is different to the input size (torch.Size([54, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "​Train Epoch: 0 Loss = 25902001.859375\n",
      "​Train Epoch: 1 Loss = 24753189.46875\n",
      "​Train Epoch: 2 Loss = 22962756.171875\n",
      "​Train Epoch: 3 Loss = 20613063.890625\n",
      "​Train Epoch: 4 Loss = 17866483.15625\n",
      "​Train Epoch: 5 Loss = 14928023.3046875\n",
      "​Train Epoch: 6 Loss = 11915736.921875\n",
      "​Train Epoch: 7 Loss = 9124103.42578125\n",
      "​Train Epoch: 8 Loss = 6708469.98046875\n",
      "​Train Epoch: 9 Loss = 4743699.642578125\n",
      "​Train Epoch: 10 Loss = 3219426.6279296875\n",
      "​Train Epoch: 11 Loss = 2134055.00390625\n",
      "​Train Epoch: 12 Loss = 1433756.3276367188\n",
      "​Train Epoch: 13 Loss = 977726.8159179688\n",
      "​Train Epoch: 14 Loss = 728022.423828125\n",
      "​Train Epoch: 15 Loss = 602901.9213867188\n",
      "​Train Epoch: 16 Loss = 532882.2216796875\n",
      "​Train Epoch: 17 Loss = 503741.3361816406\n",
      "​Train Epoch: 18 Loss = 492512.28515625\n",
      "​Train Epoch: 19 Loss = 485053.87658691406\n",
      "​Train Epoch: 20 Loss = 481532.30859375\n",
      "​Train Epoch: 21 Loss = 477646.4372558594\n",
      "​Train Epoch: 22 Loss = 475444.59411621094\n",
      "​Train Epoch: 23 Loss = 474510.5021972656\n",
      "​Train Epoch: 24 Loss = 474526.892578125\n",
      "​Train Epoch: 25 Loss = 473543.66564941406\n",
      "​Train Epoch: 26 Loss = 473127.3271484375\n",
      "​Train Epoch: 27 Loss = 472544.6809082031\n",
      "​Train Epoch: 28 Loss = 473259.3586425781\n",
      "​Train Epoch: 29 Loss = 471344.4948730469\n",
      "​Train Epoch: 30 Loss = 470963.16271972656\n",
      "​Train Epoch: 31 Loss = 471270.3923339844\n",
      "​Train Epoch: 32 Loss = 472887.1544189453\n",
      "​Train Epoch: 33 Loss = 472137.4658203125\n",
      "​Train Epoch: 34 Loss = 470817.3165283203\n",
      "​Train Epoch: 35 Loss = 469419.6286621094\n",
      "​Train Epoch: 36 Loss = 471014.9743652344\n",
      "​Train Epoch: 37 Loss = 472144.8762207031\n",
      "​Train Epoch: 38 Loss = 470504.8488769531\n",
      "​Train Epoch: 39 Loss = 470324.0185546875\n",
      "​Train Epoch: 40 Loss = 470336.1120605469\n",
      "​Train Epoch: 41 Loss = 469157.4216308594\n",
      "​Train Epoch: 42 Loss = 470473.7038574219\n",
      "​Train Epoch: 43 Loss = 470111.7951660156\n",
      "​Train Epoch: 44 Loss = 468174.822265625\n",
      "​Train Epoch: 45 Loss = 470140.76220703125\n",
      "​Train Epoch: 46 Loss = 469922.27783203125\n",
      "​Train Epoch: 47 Loss = 470250.9729003906\n",
      "​Train Epoch: 48 Loss = 469146.353515625\n",
      "​Train Epoch: 49 Loss = 469220.8006591797\n",
      "​Train Epoch: 50 Loss = 469968.6494140625\n",
      "​Train Epoch: 51 Loss = 469055.3547363281\n",
      "​Train Epoch: 52 Loss = 469234.6354980469\n",
      "​Train Epoch: 53 Loss = 468570.26318359375\n",
      "​Train Epoch: 54 Loss = 469274.41760253906\n",
      "​Train Epoch: 55 Loss = 470754.8869628906\n",
      "​Train Epoch: 56 Loss = 472650.83068847656\n",
      "​Train Epoch: 57 Loss = 469337.3271484375\n",
      "​Train Epoch: 58 Loss = 469097.54248046875\n",
      "​Train Epoch: 59 Loss = 468582.62841796875\n",
      "​Train Epoch: 60 Loss = 468364.2587890625\n",
      "​Train Epoch: 61 Loss = 468140.17138671875\n",
      "​Train Epoch: 62 Loss = 468461.7276611328\n",
      "​Train Epoch: 63 Loss = 468944.0809326172\n",
      "​Train Epoch: 64 Loss = 468221.7517089844\n",
      "​Train Epoch: 65 Loss = 468305.0634765625\n",
      "​Train Epoch: 66 Loss = 467939.09313964844\n",
      "​Train Epoch: 67 Loss = 468350.1298828125\n",
      "​Train Epoch: 68 Loss = 468575.1837158203\n",
      "​Train Epoch: 69 Loss = 468453.03771972656\n",
      "​Train Epoch: 70 Loss = 468333.0939941406\n",
      "​Train Epoch: 71 Loss = 467740.3465576172\n",
      "​Train Epoch: 72 Loss = 469228.0544433594\n",
      "​Train Epoch: 73 Loss = 467219.0979003906\n",
      "​Train Epoch: 74 Loss = 467676.55725097656\n",
      "​Train Epoch: 75 Loss = 468755.81201171875\n",
      "​Train Epoch: 76 Loss = 468151.1330566406\n",
      "​Train Epoch: 77 Loss = 467970.67236328125\n",
      "​Train Epoch: 78 Loss = 468088.62841796875\n",
      "​Train Epoch: 79 Loss = 468183.7205810547\n",
      "​Train Epoch: 80 Loss = 468435.6134033203\n",
      "​Train Epoch: 81 Loss = 467970.1389160156\n",
      "​Train Epoch: 82 Loss = 467036.86865234375\n",
      "​Train Epoch: 83 Loss = 467739.5205078125\n",
      "​Train Epoch: 84 Loss = 467744.40856933594\n",
      "​Train Epoch: 85 Loss = 467791.4913330078\n",
      "​Train Epoch: 86 Loss = 467245.56298828125\n",
      "​Train Epoch: 87 Loss = 467823.4924316406\n",
      "​Train Epoch: 88 Loss = 467246.25549316406\n",
      "​Train Epoch: 89 Loss = 467088.93115234375\n",
      "​Train Epoch: 90 Loss = 467917.1805419922\n",
      "​Train Epoch: 91 Loss = 467581.86279296875\n",
      "​Train Epoch: 92 Loss = 467807.3942871094\n",
      "​Train Epoch: 93 Loss = 468080.33935546875\n",
      "​Train Epoch: 94 Loss = 467466.15625\n",
      "​Train Epoch: 95 Loss = 468706.26623535156\n",
      "​Train Epoch: 96 Loss = 467612.2980957031\n",
      "​Train Epoch: 97 Loss = 467927.6799316406\n",
      "​Train Epoch: 98 Loss = 467967.10693359375\n",
      "​Train Epoch: 99 Loss = 467856.2639160156\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "def train_model(model, train_loader, criterion, T):\n",
    "  model.train()\n",
    "  opt = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.1)\n",
    "  # opt = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "  for epoch in range(T): \n",
    "      running_loss = 0\n",
    "      for data in enumerate(train_loader):\n",
    "          ct_data, actual_age = data[1][0], data[1][1]\n",
    "          opt.zero_grad()\n",
    "          predicted_age = model(ct_data)      \n",
    "          loss = criterion(predicted_age, actual_age)\n",
    "          running_loss += loss.item()*train_loader.batch_size\n",
    "          loss.backward() \n",
    "          opt.step()\n",
    "          \n",
    "      print(\"​Train Epoch: \"+str(epoch) + \" Loss =\", str(running_loss))\n",
    "\n",
    "  model.train(mode=False)\n",
    "\n",
    "model = build_model()\n",
    "train_model(model, train_set, criterion, T = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WHHHQ7dzNrwH"
   },
   "outputs": [],
   "source": [
    "b = CT_Dataset(X=X_test, y = y_test)\n",
    "test_set = DataLoader(b, batch_size=64)\n",
    "# train_set = DataLoader(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-1z56dnZcFr",
    "outputId": "55f88d0c-39d1-47f4-f7ec-86742357af7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanyamkakkar/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([56])) that is different to the input size (torch.Size([56, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "910.386360168457"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, criterion):\n",
    "  model.eval()\n",
    "  running_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for data in enumerate(test_loader):\n",
    "          ct_data, actual_age = data[1][0], data[1][1]\n",
    "          predicted_age = model(ct_data)\n",
    "          loss = criterion(predicted_age, actual_age)\n",
    "          running_loss += loss.item()\n",
    "  return running_loss\n",
    "\n",
    "evaluate_model(model, test_set, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EMDTR4K7Ox4w"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS760 Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
